{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRGkuracAkoj",
        "outputId": "e39395dc-342b-4c32-8e0e-10a64b4e19c5",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:01.788606Z",
          "start_time": "2025-10-30T21:13:01.636466Z"
        }
      },
      "source": [
        "!python --version"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ],
      "execution_count": 67
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THMEU_T4r5GS",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:03.557396Z",
          "start_time": "2025-10-30T21:13:01.789617Z"
        }
      },
      "source": [
        "# Install dependencies\n",
        "!pip install -q --upgrade numerapi pandas pyarrow matplotlib lightgbm scikit-learn scipy cloudpickle==3.1.1\n",
        "!pip install -q --no-deps numerai-tools\n",
        "\n",
        "# Inline plots\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B4bbH07r5GU",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:03.945679Z",
          "start_time": "2025-10-30T21:13:03.558369Z"
        }
      },
      "source": [
        "# Initialize NumerAPI - the official Python API client for Numerai\n",
        "from numerapi import NumerAPI\n",
        "napi = NumerAPI()\n",
        "\n",
        "\n",
        "DEBUG = True\n",
        "\n",
        "\n",
        "\n",
        "# list the datasets and available versions\n",
        "all_datasets = napi.list_datasets()\n",
        "dataset_versions = list(set(d.split('/')[0] for d in all_datasets))\n",
        "print(\"Available versions:\\n\", dataset_versions)\n",
        "\n",
        "# Set data version to one of the latest datasets\n",
        "DATA_VERSION = \"v5.1\"\n",
        "\n",
        "# Print all files available for download for our version\n",
        "current_version_files = [f for f in all_datasets if f.startswith(DATA_VERSION)]\n",
        "print(\"Available\", DATA_VERSION, \"files:\\n\", current_version_files)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mldufeo9BKS",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:04.465165Z",
          "start_time": "2025-10-30T21:13:03.946744Z"
        }
      },
      "source": [
        "import json\n",
        "\n",
        "# download the feature metadata file\n",
        "napi.download_dataset(f\"{DATA_VERSION}/features.json\")\n",
        "\n",
        "# read the metadata and display\n",
        "feature_metadata = json.load(open(f\"{DATA_VERSION}/features.json\"))\n",
        "for metadata in feature_metadata:\n",
        "  print(metadata, len(feature_metadata[metadata]))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sESS7Wfs_pqz"
      },
      "source": [
        "### Feature Sets & Groups\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeAzyU9q_dwR",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:04.468769Z",
          "start_time": "2025-10-30T21:13:04.466206Z"
        }
      },
      "source": [
        "feature_sets = feature_metadata[\"feature_sets\"]\n",
        "for feature_set in [\"small\", \"medium\", \"all\"]:\n",
        "  print(feature_set, len(feature_sets[feature_set]))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC5YkX1xr5GV",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:06.047620Z",
          "start_time": "2025-10-30T21:13:04.469578Z"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- scegliamo il set di feature ---\n",
        "# \"small\" = più leggero, \"medium\" = più potente (ma più RAM)\n",
        "feature_set = feature_metadata[\"feature_sets\"][\"small\"]  # puoi provare \"medium\" quando ti senti\n",
        "\n",
        "# --- scegliamo i target per il multi-target ensemble ---\n",
        "all_targets = feature_metadata[\"targets\"]\n",
        "target_cols = [\"target\"]\n",
        "target_cols = [\"target\"] if DEBUG else [\"target\"] + [t for t in all_targets if t != \"target\"][:3]\n",
        "\n",
        "\n",
        "print(\"Useremo questi target:\", target_cols)\n",
        "print(\"Numero di feature:\", len(feature_set))\n",
        "\n",
        "# --- scarica e carica il train ---\n",
        "napi.download_dataset(f\"{DATA_VERSION}/train.parquet\")\n",
        "train = pd.read_parquet(\n",
        "    f\"{DATA_VERSION}/train.parquet\",\n",
        "    columns=[\"era\"] + target_cols + feature_set\n",
        ")\n",
        "\n",
        "# --- Memory helper: tieni solo le ultime MAX_ERAS ere ---\n",
        "MAX_ERAS = 80 if DEBUG else 300\n",
        "unique_eras = np.sort(train[\"era\"].unique())\n",
        "if len(unique_eras) > MAX_ERAS:\n",
        "    keep_eras = unique_eras[-MAX_ERAS:]\n",
        "    train = train[train[\"era\"].isin(keep_eras)].copy()\n",
        "    print(f\"Kept last {MAX_ERAS} eras -> {len(train)} rows\")\n",
        "else:\n",
        "    print(f\"Using all {len(unique_eras)} eras -> {len(train)} rows\")\n",
        "\n",
        "# --- cast a float32 per risparmiare RAM ---\n",
        "for col in feature_set:\n",
        "    train[col] = train[col].astype(\"float32\")\n",
        "for t in target_cols:\n",
        "    train[t] = train[t].astype(\"float32\")\n",
        "\n",
        "# mantieni 'id' come index come nell'hello world\n",
        "train.reset_index(drop=False, inplace=True)\n",
        "train.set_index(\"id\", inplace=True)\n",
        "\n",
        "print(\"Train dtypes set to float32, shape:\", train.shape)\n",
        "train\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBcMKMX6FoNl"
      },
      "source": [
        "\n",
        "### Training data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9JOOMqpFscM",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:06.117675Z",
          "start_time": "2025-10-30T21:13:06.048265Z"
        }
      },
      "source": [],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSvdym9wr5GW"
      },
      "source": [
        "### Eras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JX0Bs95r5GX",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:06.199103Z",
          "start_time": "2025-10-30T21:13:06.118521Z"
        }
      },
      "source": [
        "# Plot the number of rows per era\n",
        "train.groupby(\"era\").size().plot(\n",
        "    title=\"Number of rows per era\",\n",
        "    figsize=(5, 3),\n",
        "    xlabel=\"Era\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxQCUEEPr5GZ"
      },
      "source": [
        "### Target\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ALp0YQ6r5GZ",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:06.322886Z",
          "start_time": "2025-10-30T21:13:06.199766Z"
        }
      },
      "source": [
        "# Plot density histogram of the target\n",
        "train[\"target\"].plot(\n",
        "  kind=\"hist\",\n",
        "  title=\"Target\",\n",
        "  figsize=(5, 3),\n",
        "  xlabel=\"Value\",\n",
        "  density=True,\n",
        "  bins=50\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhj9RZGNr5GX"
      },
      "source": [
        "### Features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHlSJccVr5GY",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:06.496435Z",
          "start_time": "2025-10-30T21:13:06.323589Z"
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
        "first_era = train[train[\"era\"] == train[\"era\"].unique()[0]]\n",
        "last_era = train[train[\"era\"] == train[\"era\"].unique()[-1]]\n",
        "last_era[feature_set[-1]].plot(\n",
        "   title=\"5 equal bins\",\n",
        "   kind=\"hist\",\n",
        "   density=True,\n",
        "   bins=50,\n",
        "   ax=ax1\n",
        ")\n",
        "first_era[feature_set[-1]].plot(\n",
        "   title=\"missing data\",\n",
        "   kind=\"hist\",\n",
        "   density=True,\n",
        "   bins=50,\n",
        "   ax=ax2\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyn-0Or3r5GZ"
      },
      "source": [
        "## 2. Modeling\n",
        "\n",
        "\n",
        "### Model training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prHdeg5Nr5GZ",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:27.543494Z",
          "start_time": "2025-10-30T21:13:06.497325Z"
        }
      },
      "source": [
        "# 2. Modeling — ensemble avanzato (versione ottimizzata per Colab)\n",
        "import gc\n",
        "import lightgbm as lgb\n",
        "from sklearn.decomposition import PCA\n",
        "from numerai_tools.scoring import numerai_corr\n",
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Usa il DEBUG definito sopra nel notebook, se esiste\n",
        "DEBUG = globals().get(\"DEBUG\", False)\n",
        "\n",
        "def make_era_splits(\n",
        "    eras: np.ndarray,\n",
        "    n_splits: int = 4,\n",
        "    embargo_eras: int = 4\n",
        ") -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    \"\"\"\n",
        "    Crea splits walk-forward per era con embargo.\n",
        "    \"\"\"\n",
        "    eras = np.sort(np.unique(eras))\n",
        "    n_eras = len(eras)\n",
        "    split_size = n_eras // (n_splits + 1)\n",
        "\n",
        "    splits: List[Tuple[np.ndarray, np.ndarray]] = []\n",
        "    for i in range(n_splits):\n",
        "        train_end = split_size * (i + 1)\n",
        "        val_start = train_end + embargo_eras\n",
        "        val_end = min(val_start + split_size, n_eras)\n",
        "\n",
        "        if val_start >= n_eras or val_start >= val_end:\n",
        "            break\n",
        "\n",
        "        train_eras = eras[:train_end]\n",
        "        val_eras = eras[val_start:val_end]\n",
        "        splits.append((train_eras, val_eras))\n",
        "    return splits\n",
        "\n",
        "\n",
        "def eras_to_index(df: pd.DataFrame, train_eras, val_eras):\n",
        "    train_idx = df.index[df[\"era\"].isin(train_eras)].values\n",
        "    val_idx = df.index[df[\"era\"].isin(val_eras)].values\n",
        "    return train_idx, val_idx\n",
        "\n",
        "\n",
        "def neutralize_series(\n",
        "    series: pd.Series,\n",
        "    exposures: np.ndarray,\n",
        "    proportion: float = 1.0\n",
        ") -> pd.Series:\n",
        "    \"\"\"\n",
        "    Neutralizza le previsioni rispetto alle componenti principali (PCA) delle feature.\n",
        "    \"\"\"\n",
        "    s = series.values.reshape(-1, 1)\n",
        "    x = exposures\n",
        "\n",
        "    # normalizza ogni colonna di exposure\n",
        "    x = x / (np.sqrt((x ** 2).sum(axis=0, keepdims=True)) + 1e-8)\n",
        "\n",
        "    # proiezione e rimozione della componente spiegata\n",
        "    correction = x @ np.linalg.pinv(x).dot(s)\n",
        "    neutralized = s - proportion * correction\n",
        "    neutralized = neutralized.ravel()\n",
        "\n",
        "    # standardizza (z-score)\n",
        "    neutralized = (neutralized - neutralized.mean()) / (neutralized.std() + 1e-8)\n",
        "    return pd.Series(neutralized, index=series.index)\n",
        "\n",
        "\n",
        "def to_rank(preds: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Converte in rank normalizzato (molto importante per Numerai).\n",
        "    Range ~ [-0.5, 0.5].\n",
        "    \"\"\"\n",
        "    return preds.rank(method=\"first\").values / (len(preds) + 1) - 0.5\n",
        "\n",
        "\n",
        "class NumeraiEnsembleModel:\n",
        "    def __init__(\n",
        "        self,\n",
        "        feature_cols,\n",
        "        target_cols,\n",
        "        n_splits: int = 4,\n",
        "        embargo_eras: int = 4\n",
        "    ):\n",
        "        self.feature_cols = feature_cols\n",
        "        self.target_cols = target_cols\n",
        "        self.n_splits = n_splits\n",
        "        self.embargo_eras = embargo_eras\n",
        "\n",
        "        self.models = {t: [] for t in target_cols}\n",
        "        self.target_weights = {t: 1.0 for t in target_cols}\n",
        "        self.pca = None\n",
        "        self.per_era_corr = {}\n",
        "\n",
        "    def _lgb_params(self):\n",
        "        \"\"\"\n",
        "        Parametri un po' più leggeri ma comunque aggressivi.\n",
        "        In DEBUG abbassiamo n_estimators per andare più veloci.\n",
        "        \"\"\"\n",
        "        return dict(\n",
        "            objective=\"regression\",\n",
        "            n_estimators=512 if DEBUG else 2048,\n",
        "            learning_rate=0.02,\n",
        "            max_depth=-1,           # lascia l'albero libero\n",
        "            num_leaves=255,\n",
        "            # CHIAVE: permetti a LightGBM di fare split\n",
        "            min_data_in_leaf=100,   # prima era 4000 (troppo grande)\n",
        "            # uso nomi \"classici\" LGBMRegressor\n",
        "            colsample_bytree=0.4,\n",
        "            subsample=0.8,\n",
        "            subsample_freq=1,\n",
        "            reg_lambda=0.1,         # L2 regularization\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "    def fit(self, train: pd.DataFrame):\n",
        "        eras = train[\"era\"].values\n",
        "        splits = make_era_splits(\n",
        "            eras,\n",
        "            n_splits=self.n_splits,\n",
        "            embargo_eras=self.embargo_eras\n",
        "        )\n",
        "\n",
        "        # --- PCA su un campione per non ammazzare la RAM ---\n",
        "        pca_sample = train[self.feature_cols].sample(\n",
        "            n=min(300_000, len(train)),\n",
        "            random_state=42\n",
        "        )\n",
        "        n_pcs = min(8, len(self.feature_cols))\n",
        "        self.pca = PCA(n_components=n_pcs, random_state=42)\n",
        "        self.pca.fit(pca_sample.values)\n",
        "\n",
        "        # Out-of-fold predictions per target (per pesare i target)\n",
        "        self.oof_preds = {\n",
        "            t: pd.Series(0.0, index=train.index, dtype=\"float32\")\n",
        "            for t in self.target_cols\n",
        "        }\n",
        "        self.oof_counts = {\n",
        "            t: pd.Series(0, index=train.index, dtype=\"int32\")\n",
        "            for t in self.target_cols\n",
        "        }\n",
        "        self.per_era_corr = {t: None for t in self.target_cols}\n",
        "\n",
        "        for split_id, (train_eras, val_eras) in enumerate(splits):\n",
        "            print(f\"=== Split {split_id+1}/{len(splits)} ===\")\n",
        "\n",
        "            tr_idx, val_idx = eras_to_index(train, train_eras, val_eras)\n",
        "            X_tr = train.loc[tr_idx, self.feature_cols].astype(\"float32\")\n",
        "            X_val = train.loc[val_idx, self.feature_cols].astype(\"float32\")\n",
        "\n",
        "            expo_tr = self.pca.transform(X_tr.values)\n",
        "            expo_val = self.pca.transform(X_val.values)\n",
        "\n",
        "            for target in self.target_cols:\n",
        "                y_tr = train.loc[tr_idx, target].astype(\"float32\")\n",
        "                y_val = train.loc[val_idx, target].astype(\"float32\")\n",
        "\n",
        "                model = lgb.LGBMRegressor(**self._lgb_params())\n",
        "                model.fit(\n",
        "                    X_tr, y_tr,\n",
        "                    eval_set=[(X_val, y_val)],\n",
        "                    eval_metric=\"l2\",\n",
        "                    callbacks=[\n",
        "                        lgb.early_stopping(\n",
        "                            stopping_rounds=100,\n",
        "                            verbose=False\n",
        "                        )\n",
        "                    ]\n",
        "                )\n",
        "\n",
        "                self.models[target].append(model)\n",
        "\n",
        "                val_raw = pd.Series(\n",
        "                    model.predict(X_val),\n",
        "                    index=train.loc[val_idx].index\n",
        "                )\n",
        "                val_neut = neutralize_series(val_raw, expo_val, proportion=1.0)\n",
        "                val_pred = to_rank(val_neut).astype(\"float32\")\n",
        "\n",
        "                # niente FutureWarning: castiamo a float32 prima\n",
        "                self.oof_preds[target].loc[val_idx] += val_pred\n",
        "                self.oof_counts[target].loc[val_idx] += 1\n",
        "\n",
        "            # libera RAM a ogni split\n",
        "            del X_tr, X_val, expo_tr, expo_val, y_tr, y_val\n",
        "            gc.collect()\n",
        "\n",
        "        # media OOF per ogni target\n",
        "        for t in self.target_cols:\n",
        "            mask = self.oof_counts[t] > 0\n",
        "            # solo dove abbiamo almeno una predizione OOF\n",
        "            self.oof_preds[t].loc[mask] = (\n",
        "                self.oof_preds[t].loc[mask] / self.oof_counts[t].loc[mask]\n",
        "            )\n",
        "            # dove non abbiamo OOF, mettiamo NaN\n",
        "            self.oof_preds[t].loc[~mask] = np.nan\n",
        "\n",
        "        # calcolo sharpe per target, da usare come peso\n",
        "        for t in self.target_cols:\n",
        "            print(f\"\\n### Valutazione target {t} (OOF) ###\")\n",
        "\n",
        "            df_tmp = train[[\"era\", t]].copy()\n",
        "            df_tmp[\"prediction\"] = self.oof_preds[t]\n",
        "\n",
        "            # tieni solo righe con OOF prediction valida\n",
        "            df_tmp = df_tmp.dropna(subset=[\"prediction\", t])\n",
        "\n",
        "            if df_tmp.empty:\n",
        "                print(\"Nessuna OOF valida per questo target, Sharpe = 0\")\n",
        "                self.per_era_corr[t] = pd.Series(dtype=\"float32\")\n",
        "                self.target_weights[t] = 0.0\n",
        "                continue\n",
        "\n",
        "            per_era_corr = df_tmp.groupby(\"era\", observed=True).apply(\n",
        "                lambda x: numerai_corr(x[[\"prediction\"]], x[t]),\n",
        "                include_groups=False,\n",
        "            )\n",
        "\n",
        "            # numerai_corr può restituire Series: convertiamo in float\n",
        "            if isinstance(per_era_corr.iloc[0], pd.Series):\n",
        "                per_era_corr_vals = per_era_corr.apply(lambda s: float(s.values[0]))\n",
        "            else:\n",
        "                per_era_corr_vals = per_era_corr.astype(float)\n",
        "\n",
        "            # ripulisci NaN e inf\n",
        "            per_era_corr_vals = per_era_corr_vals.replace(\n",
        "                [np.inf, -np.inf], np.nan\n",
        "            ).dropna()\n",
        "\n",
        "            if len(per_era_corr_vals) == 0:\n",
        "                print(\"Tutte le CORR per era sono NaN, Sharpe = 0\")\n",
        "                self.per_era_corr[t] = per_era_corr_vals\n",
        "                mean_corr = 0.0\n",
        "                std_corr = 0.0\n",
        "                sharpe = 0.0\n",
        "            else:\n",
        "                self.per_era_corr[t] = per_era_corr_vals\n",
        "                mean_corr = per_era_corr_vals.mean()\n",
        "                std_corr = per_era_corr_vals.std(ddof=0)\n",
        "\n",
        "                # se lo std è praticamente 0, evitiamo Sharpe assurdi\n",
        "                if std_corr < 1e-4:\n",
        "                    sharpe = 0.0\n",
        "                else:\n",
        "                    sharpe = mean_corr / std_corr\n",
        "\n",
        "            print(f\"mean CORR: {mean_corr:.5f}\")\n",
        "            print(f\"std CORR: {std_corr:.5f}\")\n",
        "            print(f\"Sharpe: {sharpe:.3f}\")\n",
        "\n",
        "            # usiamo solo Sharpe non-negativo\n",
        "            self.target_weights[t] = max(float(sharpe), 0.0)\n",
        "\n",
        "        # normalizziamo i pesi per i target, gestendo NaN / casi degeneri\n",
        "        total_w = sum(\n",
        "            w for w in self.target_weights.values()\n",
        "            if np.isfinite(w)\n",
        "        )\n",
        "\n",
        "        if (not np.isfinite(total_w)) or (total_w <= 0):\n",
        "            # fallback: pesi uguali\n",
        "            self.target_weights = {t: 1.0 for t in self.target_cols}\n",
        "            total_w = float(len(self.target_cols))\n",
        "\n",
        "        for t in self.target_cols:\n",
        "            self.target_weights[t] = float(self.target_weights[t]) / total_w\n",
        "            # nel caso fosse rimasto NaN\n",
        "            if not np.isfinite(self.target_weights[t]):\n",
        "                self.target_weights[t] = 1.0 / total_w\n",
        "\n",
        "        print(\"\\nPesi finali dei target nel meta-ensemble:\")\n",
        "        for t, w in self.target_weights.items():\n",
        "            print(f\"{t}: {w:.3f}\")\n",
        "\n",
        "    def _predict_single_target(self, df: pd.DataFrame, target: str) -> pd.Series:\n",
        "        X = df[self.feature_cols].astype(\"float32\")\n",
        "        expo = self.pca.transform(X.values)\n",
        "\n",
        "        preds_raw = np.mean(\n",
        "            [m.predict(X) for m in self.models[target]],\n",
        "            axis=0\n",
        "        )\n",
        "\n",
        "        s_raw = pd.Series(preds_raw, index=df.index)\n",
        "        s_neut = neutralize_series(s_raw, expo, proportion=1.0)\n",
        "        s_rank = to_rank(s_neut)\n",
        "\n",
        "        return s_rank\n",
        "\n",
        "    def predict(self, df: pd.DataFrame) -> pd.Series:\n",
        "        \"\"\"\n",
        "        Ritorna sempre un pandas.Series indicizzato come df.index\n",
        "        (mai un numpy array), così possiamo usare .to_frame(\"prediction\").\n",
        "        \"\"\"\n",
        "        target_preds = {}\n",
        "        for t in self.target_cols:\n",
        "            target_preds[t] = self._predict_single_target(df, t)\n",
        "\n",
        "        final = None\n",
        "        for t, s in target_preds.items():\n",
        "            w = self.target_weights.get(t, 1.0 / len(self.target_cols))\n",
        "            if final is None:\n",
        "                final = w * s\n",
        "            else:\n",
        "                final = final + w * s\n",
        "\n",
        "        # fallback difensivo\n",
        "        if final is None:\n",
        "            final = pd.Series(0.5, index=df.index, dtype=\"float32\")\n",
        "\n",
        "        # se per qualche motivo fosse un array, convertiamo\n",
        "        if not isinstance(final, pd.Series):\n",
        "            final = pd.Series(final, index=df.index)\n",
        "\n",
        "        return final\n",
        "\n",
        "\n",
        "# --- allena il modello ensemble sul train ---\n",
        "ensemble_model = NumeraiEnsembleModel(\n",
        "    feature_cols=feature_set,\n",
        "    target_cols=target_cols,\n",
        "    n_splits=2 if DEBUG else 4,   # meno split in DEBUG per andare piu veloce\n",
        "    embargo_eras=4\n",
        ")\n",
        "ensemble_model.fit(train)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTqgml-br5Ga"
      },
      "source": [
        "### Validation predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImonnvQYr5Ga",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:37.417197Z",
          "start_time": "2025-10-30T21:13:27.544461Z"
        }
      },
      "source": [
        "# Validation predictions con ensemble\n",
        "\n",
        "napi.download_dataset(f\"{DATA_VERSION}/validation.parquet\")\n",
        "\n",
        "validation = pd.read_parquet(\n",
        "    f\"{DATA_VERSION}/validation.parquet\",\n",
        "    columns=[\"era\", \"data_type\"] + target_cols + feature_set\n",
        ")\n",
        "validation = validation[validation[\"data_type\"] == \"validation\"].copy()\n",
        "del validation[\"data_type\"]\n",
        "\n",
        "# (opzionale) downsample per test veloce\n",
        "# validation = validation[validation[\"era\"].isin(validation[\"era\"].unique()[::2])]\n",
        "\n",
        "# embargo iniziale come nell'hello world\n",
        "last_train_era = int(train[\"era\"].unique()[-1])\n",
        "eras_to_embargo = [str(era).zfill(4) for era in [last_train_era + i for i in range(4)]]\n",
        "validation = validation[~validation[\"era\"].isin(eras_to_embargo)]\n",
        "\n",
        "# prediction con ensemble\n",
        "validation[\"prediction\"] = ensemble_model.predict(validation)\n",
        "\n",
        "validation[[\"era\", \"prediction\", \"target\"]]\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toGRSHN9r5Ga"
      },
      "source": [
        "### Performance evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTdo3r_Kr5Ga",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:38.485263Z",
          "start_time": "2025-10-30T21:13:37.417812Z"
        }
      },
      "source": [
        "# Performance evaluation con ensemble (CORR + MMC) — versione ripulita\n",
        "from numerai_tools.scoring import numerai_corr, correlation_contribution\n",
        "\n",
        "# scarica meta_model per le ere di validation\n",
        "napi.download_dataset(\"v4.3/meta_model.parquet\", round_num=842)\n",
        "meta_model = pd.read_parquet(\"v4.3/meta_model.parquet\")[\"numerai_meta_model\"]\n",
        "\n",
        "validation[\"meta_model\"] = meta_model.reindex(validation.index)\n",
        "\n",
        "# CORR per era\n",
        "per_era_corr = validation.groupby(\"era\", observed=True).apply(\n",
        "    lambda x: numerai_corr(\n",
        "        x[[\"prediction\"]].dropna(),\n",
        "        x[\"target\"].dropna()\n",
        "    ),\n",
        "    include_groups=False,\n",
        ")\n",
        "\n",
        "# MMC per era\n",
        "per_era_mmc = validation.dropna().groupby(\"era\", observed=True).apply(\n",
        "    lambda x: correlation_contribution(\n",
        "        x[[\"prediction\"]],\n",
        "        x[\"meta_model\"],\n",
        "        x[\"target\"]\n",
        "    ),\n",
        "    include_groups=False,\n",
        ")\n",
        "\n",
        "# convertiamo in float se necessario (numerai_corr / mmc possono dare Series)\n",
        "if isinstance(per_era_corr.iloc[0], pd.Series):\n",
        "    per_era_corr_vals = per_era_corr.apply(lambda s: float(s.values[0]))\n",
        "    per_era_mmc_vals = per_era_mmc.apply(lambda s: float(s.values[0]))\n",
        "else:\n",
        "    per_era_corr_vals = per_era_corr.astype(float)\n",
        "    per_era_mmc_vals = per_era_mmc.astype(float)\n",
        "\n",
        "# Plot per-era (CORR e MMC)\n",
        "per_era_corr_vals.plot(\n",
        "    title=\"Validation CORR (ensemble)\",\n",
        "    kind=\"bar\",\n",
        "    figsize=(8, 4),\n",
        "    xticks=[],\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "per_era_mmc_vals.plot(\n",
        "    title=\"Validation MMC (ensemble)\",\n",
        "    kind=\"bar\",\n",
        "    figsize=(8, 4),\n",
        "    xticks=[],\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "# Plot cumulativo\n",
        "per_era_corr_vals.cumsum().plot(\n",
        "    title=\"Cumulative Validation CORR\",\n",
        "    kind=\"line\",\n",
        "    figsize=(8, 4),\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "per_era_mmc_vals.cumsum().plot(\n",
        "    title=\"Cumulative Validation MMC\",\n",
        "    kind=\"line\",\n",
        "    figsize=(8, 4),\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "# metriche riassuntive (numeri scalari, niente \"prediction ... dtype: float64\")\n",
        "def summarize(series: pd.Series):\n",
        "    series = series.astype(float)\n",
        "    mean = series.mean()\n",
        "    std = series.std(ddof=0)\n",
        "    sharpe = mean / (std + 1e-8)\n",
        "    mdd = (series.cumsum().expanding(min_periods=1).max() - series.cumsum()).max()\n",
        "    return mean, std, sharpe, mdd\n",
        "\n",
        "corr_mean, corr_std, corr_sharpe, corr_mdd = summarize(per_era_corr_vals)\n",
        "mmc_mean, mmc_std, mmc_sharpe, mmc_mdd = summarize(per_era_mmc_vals)\n",
        "\n",
        "metrics_df = pd.DataFrame(\n",
        "    {\n",
        "        \"mean\": [corr_mean, mmc_mean],\n",
        "        \"std\": [corr_std, mmc_std],\n",
        "        \"sharpe\": [corr_sharpe, mmc_sharpe],\n",
        "        \"max_drawdown\": [corr_mdd, mmc_mdd],\n",
        "    },\n",
        "    index=[\"CORR\", \"MMC\"],\n",
        ")\n",
        "\n",
        "metrics_df\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gC06mZ-r5Gc"
      },
      "source": [
        "## 3. Submissions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUEWmrdnr5Gc",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:40.738515Z",
          "start_time": "2025-10-30T21:13:40.089389Z"
        }
      },
      "source": [
        "# 3. Submissions — live predictions con ensemble\n",
        "\n",
        "napi.download_dataset(f\"{DATA_VERSION}/live.parquet\")\n",
        "\n",
        "live_features = pd.read_parquet(\n",
        "    f\"{DATA_VERSION}/live.parquet\",\n",
        "    columns=feature_set\n",
        ")\n",
        "\n",
        "if DEBUG:\n",
        "    live_features = live_features.sample(n=100_000, random_state=42)\n",
        "\n",
        "live_predictions = ensemble_model.predict(live_features)\n",
        "live_submission = live_predictions.to_frame(\"prediction\")\n",
        "live_submission\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAsl2z7mr5Gd"
      },
      "source": [
        "### Model upload\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4bHP_BGr5Gd",
        "ExecuteTime": {
          "end_time": "2025-10-30T21:13:40.741709Z",
          "start_time": "2025-10-30T21:13:40.739515Z"
        }
      },
      "source": [
        "# Model upload — usa ensemble_model invece del modello semplice\n",
        "\n",
        "import cloudpickle\n",
        "import pandas as pd  # per sicurezza nel runtime Numerai\n",
        "\n",
        "def predict(live_features: pd.DataFrame,\n",
        "            _live_benchmark_models: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Funzione che Numerai chiamerà per generare le live predictions.\n",
        "    Usa l'ensemble già addestrato.\n",
        "    \"\"\"\n",
        "    preds = ensemble_model.predict(live_features)\n",
        "    return preds.to_frame(\"prediction\")\n",
        "\n",
        "with open(\"numerai_ensemble_sota.pkl\", \"wb\") as f:\n",
        "    cloudpickle.dump(predict, f)\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"numerai_ensemble_sota.pkl\")\n",
        "except:\n",
        "    pass\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.11.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}